15901	feng_pan rutu_mulkar jerry_r._hobbs	modeling and learning vague event durations for temporal reasoning	this paper report on we recent work on modeling and automatically extract vague implicit event duration from text lrb pan et al 2006a 2006b rrb it be a kind of commonsense knowledge that can have a substantial impact on temporal reasoning problem we have also propose a method of use normal distribution to model judgment that be interval on a scale and measure they interannotator agreement this should extend from time to other kind of vague but substantive information in text and commonsense reasoning event duration interannotator agreement substantial impact normal distribution commonsense reasoning	AAAI	
21083	feng_pan rutu_mulkar-mehta jerry_r._hobbs	learning event durations from event description	we have construct a corpus of news article in which event be annotated for estimate bound on they duration here we describe a method for measure inter annotator agreement for these event duration distribution we then show that machine learning technique apply to this datum yield coarsegrained event duration information considerably outperform a baseline and approach human performance annotator agreement event duration timebank inter finegrained	ACL	
60851	shi-qian_wu w._song li-jun_jiang s.-l._xie feng_pan wei-yun_yau surendra_ranganath	infrared face recognition by use blood perfusion data		AVBPA	
96562	xiang_zhang feng_pan wei_wang	redus find reducible subspace in high dimensional datum	find latent pattern in high dimensional datum be a important research problem with numerous application the most well know approach for high dimensional data analysis be feature selection and dimensionality reduction be widely use in many application these method aim to capture global pattern and be typically perform in the full feature space in many emerge application however scientist be interested in the local latent pattern hold by feature subspace which may be invisible via any global transformation in this paper we investigate the problem of find strong linear and nonlinear correlation hide in feature subspace of high dimensional datum we formalize this problem as identify reducible subspace in the full dimensional space intuitively a reducible subspace be a feature subspace whose intrinsic dimensionality be smaller than the number of feature we present a effective algorithm redus for find the reducible subspace two key component of we algorithm be find the overall reducible subspace and uncover the individual reducible subspace from the overall reducible subspace a broad experimental evaluation demonstrate the effectiveness of we algorithm doi 101145 14580821458209 high dimensional data feature subspace latent patterns	CIKM	University_of_North_Carolina_at_Chapel_Hill Chapel_Hill NC USA
118292	alexander_gutfraind aric_a._hagberg feng_pan	optimal interdiction of unreactive markovian evader	the interdiction problem arise in a variety of area include military logistics infectious disease control and counterterrorism in the typical formulation of network interdiction the task of the interdictor be to find a set of edge in a weighted network such that the removal of those edge would maximally increase the cost to a evader of travel on a path through the network we work be motivate by case in which the evader have incomplete information about the network or lack planning time or computational power eg when authority set up roadblock to catch bank robber the criminal do not know all the roadblock location or the best path to use for they escape we introduce a model of network interdiction in which the motion of one or more evader be describe by markov process and the evader be assume not to react to interdiction decision the interdiction objective be to find a edge set of size b that maximize the probability of capture the evader we prove that similar to the standard leastcost formulation for deterministic motion this interdiction problem be also nphard but unlike that problem we interdiction problem be submodular and the optimal solution can be approximate within 1 1e use a greedy algorithm additionally we exploit submodularity through a priority evaluation strategy that eliminate the linear complexity scaling in the number of network edge and speed up the solution by order of magnitude take together the result bring closer the goal of find realistic solution to the interdiction problem on globalscale network doi 101007 97836420192969 interdiction evader ume	CPAIOR	
207568	feng_pan jerry_r._hobbs	temporal aggregate in owltime	in this paper we describe we approach for represent	FLAIRS_Conference	
298638	zengguo_li ce_zhu feng_pan genan_feng xiaokang_yang si_wu nam_ling	a novel joint rate control scheme for the coding of multiple real time video programs		ICDCS_Workshops	Center_for_Signal_Process. Nanyang_Technol._Univ. Singapore
301622	feng_pan wei_wang leonard_mcmillan	accelerate profile queries in elevation maps	elevation map be a widely use spatial datum representation in geographical information system lrb gi rrb path on elevation map can be characterize by profile which describe relative elevation as a function of distance in this research we address the inverse of this mapping give a profile how to efficiently find path that could have generate it this be call the profile query problem profile have a wide variety of use that include register track information or even other map to a give map we describe a probabilistic model to characterize the maximal likelihood that a point lie on a path match the query profile propagation of such probability to neighbor point can effectively prune the search space this model enable we to efficiently answer query of arbitrary profile with userspecified error tolerance when compare to exist spatial index method we approach support more flexible query with order of magnitude speedup doi 101109 icde 2007367853 endpoint profile query error tolerance dem probabilistic model	ICDE	North_Carolina_Univ. Chapel_Hill NC
302059	xiang_zhang feng_pan wei_wang	care finding local linear correlation in high dimensional datum	find latent pattern in high dimensional datum be a important research problem with numerous application exist approach can be summarize into 3 category feature selection feature transformation lrb or feature projection rrb and project clustering be widely use in many application these method aim to capture global pattern and be typically perform in the full feature space in many emerge biomedical application however scientist be interested in the local latent pattern hold by feature subset which may be invisible via any global transformation in this paper we investigate the problem of find local linear correlation in high dimensional datum we goal be to find the latent pattern structure that may exist only in some subspace we formalize this problem as finding strongly correlate feature subset which be support by a large portion of the datum point due to the combinatorial nature of the problem and lack of monotonicity of the correlation measurement it be prohibitively expensive to exhaustively explore the whole search space in we algorithm care we utilize spectrum property and effective heuristic to prune the search space extensive experimental result show that we approach be effective in find local linear correlation that may not be identify by exist method doi 101109 icde 20084497421 feature transformation linear correlation pca data distribution subspace	ICDE	Department_of_Computer_Science University_of_North_Carolina_at_Chapel_Hill Chapel_Hill NC_27599 USA._panfeng@cs.unc.edu
302079	feng_pan xiang_zhang wei_wang	a general framework for fast coclustering on large dataset use matrix decomposition	simultaneously clustering column and row lrb co clustering rrb of large datum matrix be a important problem with wide application such as document mining microarray analysis and recommendation system several coclustering algorithm have be show effective in discover hidden clustering structure in the datum matrix for a data matrix of m row and n column the time complexity of these method be usually in the order of mtimesn lrb if not higher rrb this limit they applicability to datum matrix involve a large number of column and row moreover a implicit assumption make by exist coclustering method be that the whole datum matrix need to be hold in the main memory in this paper we propose a general framework crd for cocluster large dataset utilize recently develop sampling base matrix decomposition method the time complexity of we approach be linear in m and n and it do not require the whole datum matrix be in the main memory experimental result show that crd achieve competitive accuracy to exist coclustering method but with much less computational cost doi 101109 icde 20084497548 itc data matrix time complexity large datum crd	ICDE	Department_of_Computer_Science University_of_North_Carolina_at_Chapel_Hill._panfeng@cs.unc.edu
302511	gao_cong kian-lee_tan anthony_k._h._tung feng_pan	mining frequent closed patterns in microarray data	microarray datum typically contain a large number of column and a small number of row which pose a great challenge for exist frequent lrb closed rrb pattern mining algorithm that discover pattern in item enumeration space in this paper we propose two algorithm that explore the row enumeration space to mine frequent closed pattern several experiment on reallife gene expression datum show that the algorithm be faster than exist algorithm include closet charm closet and carpenter doi 101109 icdm 200410070 enumeration space charm closet frequent closed patterns several experiment	ICDM	National_University_of_Singapore
302775	feng_pan wei_wang anthony_k._h._tung jiong_yang	finding representative set from massive datum	in the information age datum be pervasive in some application datum explosion be a significant phenomenon the massive datum volume pose challenge to both human user and computer in this project we propose a new model for identify representative set from a large database a representative set be a special subset of the original dataset which have three main characteristic it be significantly smaller in size compare to the original dataset it capture the most information from the original dataset compare to other subset of the same size it have low redundancy among the representative it contain we use informationtheoretic measure such as mutual information and relative entropy to measure the representativeness of the representative set we first design a greedy algorithm and then present a heuristic algorithm that deliver much better performance we run experiment on two real dataset and evaluate the effectiveness of we representative set in term of coverage and accuracy the experiment show that we representative set attain expect characteristic and capture information more efficiently doi 101109 icdm 200569 mutual information greedy algorithm same size original dataset representative set	ICDM	University_of_North_Carolina_at_Chapel_Hill
303480	feng_pan adam_roberts leonard_mcmillan david_threadgill wei_wang	sample selection for maximal diversity	the problem of select a sample subset sufficient to preserve diversity arise in many application one example be in the design of recombinant inbred line lrb ril rrb for genetic association study in this context genetic diversity be measure by how many allele be retain in the result inbred strain ril panel that be derive from more than two parental strain such as the collaborative cross lrb churchill et al 2004 rrb present a particular challenge with regard to which of the many exist lab mouse strain should be include in the initial breeding funnel in order to maximize allele retention a similar problem occur in the study of customer review when select a subset of product with a maximal diversity in review diversity in this case imply the presence of a set of product have both positive and negative rank for each customer in this paper we demonstrate that select a optimal diversity subset be a npcomplete problem via reduction to set cover this reduction be sufficiently tight that greedy approximation to the set cover problem directly apply to maximize diversity we then suggest a slightly modify subset selection problem in which a initial greedy diversity solution be use to effectively prune a exhaustive search for all diversity subset bound from below by a specify coverage threshold extensive experiment on real dataset be perform to demonstrate the effectiveness and efficiency of we approach doi 101109 icdm 200716 pgd enumeration algorithm sample subset real dataset cover	ICDM	Univ._of_North_Carolina Chapel_Hill
303726	feng_pan lynda_yang leonard_mcmillan fernando_pardo-manuel_de_villena david_threadgill wei_wang	quantitative association analysis use tree hierarchy	association analysis arise in many important application such as bioinformatic and business intelligence give a large collection of measurement over a set of sample association analysis aim to find dependency of target variable to subset of measurement most previous algorithm adopt a twostage approach they first group sample base on the similarity in the subset of measurement and then they examine the association between these group and the specify target variable without consider the intergroup similarity or alternative grouping this can lead to case where the strength of association depend significantly on arbitrary clustering choice in this paper we propose a treebased method for quantitative association analysis tree hierarchy derive from sample similarity represent many possible sample grouping they also provide a natural way to incorporate domain knowledge such as ontology and to identify and remove outlier give a tree hierarchy we association analysis evaluate all possible grouping and select the one with strongest association to the target variable we introduce a efficient algorithm treeqa to systematically explore the searchspace of all possible grouping in a set of input tree with integrate permutation test experimental result show that treeqa be able to handlelargescale association analysis very efficiently and be more effective and robust in association analysis than previous method doi 101109 icdm 2008100 association analysis bioinformatic previous algorithm grouping target variable	ICDM	Dept._of_Comput._Sci. Univ._of_North_Carolina_at_Chapel_Hill Chapel_Hill NC
313450	qiao-ling_ji wei-min_qi wei-you_cai yuan-chu_cheng feng_pan	study of improved hierarchy genetic algorithm base on adaptive niche		ICIC_(1)	
319197	zhengguo_li feng_pan keng_pang_lim xiao_lin susanto_rahardja	adaptive rate control for h 264	this paper present a rate control scheme for h 264 by introduce the concept of basic unit and a linear prediction model the basic unit can be a macroblock lrb mb rrb a slice or a frame it can be use to obtain a tradeoff between the overall code efficiency and the bit fluctuation the linear model be use to solve the chicken and egg dilemma exist in the rate control of h 264 both constant bit rate lrb cbr rrb and variable bit rate lrb vbr rrb case be study we scheme have be adopt by h 264 doi 101016 jjvcir 200504004 rate control dilemma rdo egg mad	ICIP	
320318	feng_pan mike_keane	a new set of moment invariant for handwritten numeral recognition		ICIP_(1)	Dept._of_Exp._Phys. Univ._Coll._Galway
320329	feng_pan xiao_lin susanto_rahardja keng_pang_lim zhengguo_li dajun_wu si_wu c._all w._ye z._liang	fast intra mode decision algorithm for h 264avc video code	the emerge h264avc video code standard aim to significantly improve compression performance compare to all exist video code standard in order to achieve this a robust ratedistortion optimization lrb rdo rrb technique be employ to select the best coding mode and reference frame for each macroblock as a result the complexity and computation load increase drastically this paper present a fast mode decision algorithm for h 264 intra prediction base on local edge information prior to intra prediction a edge map be create and a local edge direction histogram be then establish for each subblock base on the distribution of the edge direction histogram only a small part of intra prediction mode be choose for rdo calculation experimental result show that the last intra mode decision scheme increase the speed of intra code significantly with negligible loss of psnr doi 101109 icip 20041419414	ICIP	
322438	xiaokang_yang ce_zhu zengguo_li genan_feng si_wu nam_ling feng_pan	a router base unequal error control scheme for video over the internet		ICIP_(2)	Labs._for_Inf._Technol. Nanyang_Technol._Univ. Singapore
323507	feng_pan yin_sun zhongkang_lu ashraf_a._kassim	complexitybased rate distortion optimization with perceptual tuning for scalable video code	this paper have propose a content adaptive ratedistortion optimization scheme for scalable video coding to adaptively determine the tradeoff between texture and motion coding the scheme first make use of spatial and temporal complexity to adjust the lagrangian multiplier for all the macroblock in a frame after that the lagrangian multiplier for every macroblock of the frame be further refine use local perceptual cue to ensure optimal local selection of the lagrangian multiplier several characteristic of human visual system have be take into account to guide the adjustment experiment have show that the propose scheme could effectively adapt the adjustment of lagrangian multiplier to video contents and the subjective quality of the reconstructed frame could be improve without compromise psnr doi 101109 icip 20051530322 psnr reference software important region rdo local	ICIP_(3)	Inst._for_Infocomm_Res. Singapore
330929	feng_pan zhengguo_li keng_pang_lim xiao_lin susanto_rahardja dajun_wu si_wu	complexity adaptive quantization for intraframe in very low bit rate video code	conventional rate control scheme focus on the problem of find a optimal quantization value for pand bframe no rate control be available for the encoding of iframe this could pose big problem due to the large number of bit a iframe could generate and due to the fact that the number of bit vary drastically from sequence to sequence depend on they image complexity this problem become severe especially at very low bit rate therefore a mechanism to allocate datum bit to a iframe accord to its complexity be indispensable in order to have constant code quality this paper present a mechanism to establish for iframe the generic relationship among the quantization value datum bit and they image complexity experimental result show that this generic relationship provide a fairly accurate estimation of quantization value for a iframe at give datum bit and image complexity and be very useful in control the datum bit generate by a iframe datum bit iframe rate control bit rate quantization value	ICME	Inst._for_Infocomm_Res. Singapore
330931	feng_pan xiao_lin susanto_rahardja keng_pang_lim zhengguo_li	a directional field base fast intra mode decision algorithm for h 264 video coding	the h 264 video code standard can achieve considerably higher code efficiency than previous standard in order to achieve this a robust ratedistortion optimization lrb rdo rrb technique be employ to select the best coding mode for each macroblock as a result the encoder complexity be increase considerably this paper present a directional field base fast intra mode decision algorithm to improve the encoder s efficiency prior to intra prediction the directional field be calculate for all the block size to decide the dominate edge direction in the block base on the edge direction information only a small number of prediction mode be choose for rdo calculation experimental result show that the fast intra mode decision algorithm increase the speed of intra code significantly with negligible loss of psnr psnr encoder rdo edge direction intra	ICME	Inst._for_Infocomm_Res. Singapore
330933	feng_pan xiao_lin susanto_rahardja keng_pang_lim zhengguo_li dajun_wu si_wu	proactive frameskipping decision scheme for variable frame rate video code	many rate control algorithm focus on the adjustment of quantisation value to retain a certain buffer level and arbitrary frameskipping be often need to keep the buffer from overflow at very low bitrate in this paper a content adaptive rate control be propose to optimise the balance between spatial and temporal quality via active frameskipping the occurrence of frameskipping be jointly dependent on the temporal and spatial quality of the video and on the fullness of the buffer this help to achieve a consistent spatial and temporal quality and to enhance the overall perceptual quality experimental result show that the new scheme be simple but very effective with large average psnr gain and consistently improve visual quality and the improvement in perceptual quality be much significant than that in average psnr s frameskipping buffer rate control frame rate temporal quality	ICME	Inst._for_Infocomm_Res. Singapore Singapore
330935	feng_pan xiao_lin susanto_rahardja ee_ping_ong weisi_lin	measure block artifact use edge direction information	blockbased transform code be the most popular approach for image and video compression the objective measurement of block artifact play a important role in the design optimization and assessment of image and video coding system this paper present a new algorithm for measure block artifact in image and video instead of use the traditional pixel discontinuity along the block boundary we use the edge directional information of the image the new algorithm do not need the exact location of the block boundary thus be invariant to the displacement rotation and scaling of the image experiment on various still image and video show that the new blockiness measure be very efficient in term of computational complexity and memory usage and can produce block artifact measurement consistent with subjective rating image and video direct quality metric block artifact bdct	ICME	
332489	hongtao_yu feng_pan zhiping_lin yin_sun	a perceptual bit allocation scheme for h 264	this paper aim at improve perceptual quality of encode video sequence and propose a new perceptual bit allocation scheme for h 264 firstly a new motion complexity measure be define to represent the amount of motion contents between two consecutive frame and be use to estimate the target bit at frame level secondly a segmentation method exploit the perceptual characteristic of the video contents be present and be use to adaptively update the lagrangian multiplier in the code mode selection at macroblock level thirdly base on the motion complexity and lagrangian multiplier update a rate control scheme for h 264 be propose experimental result show that we scheme can effectively improve the perceptual video quality as compare with the h 264 adopt rate control algorithm lsb 1 rsb moreover we scheme also achieve a average peak signaltonoise ratio gain of up to 0138 db for the test sequence doi 101109 icme 20051521423 lagrangian multiplier mode decision rate control motion complexity mad	ICME	Sch._of_Electr._&_Electron._Eng. Nanyang_Technol._Univ. Singapore
354238	feng_pan joseph_m._schimmels	efficient contact state graph generation for assembly application		ICRA	Dept._of_Mech._&_Ind._Eng. Marquette_Univ. Milwaukee WI USA
356903	feng_pan joseph_m._schimmels	robust procedure for obtaining assembly contact state extremal configuration	two important component in the selection of a admittance that facilitate forceguided assembly be the identification of 1 rrb the set of feasible contact state and 2 rrb the set of configuration that span each contact state ie the extremal configuration we present a procedure to automatically generate both set from cad model of the assembly part in the procedure all possible combination of principle contact be consider when generate hypothesize contact state the feasibility of each be then evaluate in a genetic algorithm base optimization procedure the maximum and minimum value of each of the 6 configuration variable span each contact state be obtain by again use genetic algorithm together the genetic algorithm approach the hierarchical datum structure contain the state the relationship among the state and the extremal within each state be use to provide a reliable means of identify all feasible contact state and they associate extremal configuration doi 101109 robot 20041307276	ICRA	Dept._of_Mech._&_Ind._Eng. Marquette_Univ. Milwaukee WI USA
370590	feng_pan	temporal aggregate for web services on the semantic web	in this paper we describe how we encode we temporal aggregate ontology in owl for web service on the semantic web we also present one example to show how to use the ontology to represent temporal aggregate information doi 101109 icws 2005118 owl owltime	ICWS	University_of_Southern_California
409001	vincent_w._freeh feng_pan nandini_kappiah david_k._lowenthal robert_springer	explore the energytime tradeoff in mpi programs on a powerscalable cluster	recently energy have become a important issue in highperformance computing for example supercomputer that have energy in mind such as bluegenel have be build the idea be to improve the energy efficiency of node we approach which use offtheshelf highperformance cluster node that be frequency scalable allow energy saving by scale down the cpu this paper investigate the energy consumption and execution time of application from a standard benchmark suite lrb nas rrb on a powerscalable cluster we study via direct measurement and simulation both intranode and internode effect of memory and communication bottleneck respectively additionally we compare energy consumption and execution time across different number of node we result show that a powerscalable cluster have the potential to save energy by scale the processor down to lower energy level furthermore we find that for some program it be possible to both consume less energy and execute in less time when use a larger number of node each at reduce energy additionally we develop and validate a model that enable we to predict the energytime tradeoff of larger cluster doi 101109 ipdps 2005214 destiny hpc dvf cpu gear	IPDPS	North_Carolina_State_University
410320	feng_pan vincent_w._freeh daniel_m._smith	explore the energytime tradeoff in highperformance computing	highperformance computing be and have always be performance orient however a consequence of the push towards maximum performance be increase energy consumption especially at supercomputing center moreover as peak performance be rarely attain some of this energy consumption result in little or no performance gain in addition large energy consumption cost the government a significant amount of money and waste natural resource this paper investigate the tradeoff between energy and performance through the use of processor that support frequency and voltage scaling we measure the performance and energy consumption of program from three popular benchmark set we take multiple measurement for each program use different frequency and voltage setting result show that for many program a significant decrease in energy be possible with a small increase in time we believe that this justify further investigation into parallel hpc lrb eg mpi rrb application doi 101109 ipdps 2005213	IPDPS	North_Carolina_State_University Raleigh NC
423332	feng_pan zhengguo_li keng_pang_lim xiao_lin susanto_rahardja si_wu dajun_wu	adaptive intraframe quantization for very low bit rate video code		ISCAS_(3)	Inst._for_Infocomm_Res. Singapore Singapore
423333	feng_pan xiao_lin susanto_rahardja weisi_lin ee_ping_ong susu_yao zhongkang_lu xiaokang_yang	a locallyadaptive algorithm for measure block artifact in image and video	block transform code be the most popular approach for image and video compression the objective measurement of block artifact play a important role in the design optimization and assessment of image and video coding system this paper present a new algorithm for measure image quality of a bdct code image or video it exhibit unique and useful feature lrb 1 rrb it examine the block individually so that it can measure the severity of block artifact locally lrb 2 rrb it be a onepass algorithm in the sense that the image need to be access only once lrb 3 rrb it take into account the block artifact for high bit rate image and the flatness for the very low bit rate image lrb 4 rrb the quality measure be well define in the range of 0 10 experiment on various still image and video show that the new quality measure be very efficient in term of computational complexity and memory usage and can produce consistent block artifact measurement doi 101109 iscas 20041328899 blockiness jpe block artifact block bdct	ISCAS_(3)	Inst._for_Infocomm_Res. Singapore Singapore
424997	xiaokang_yang susu_yao keng_pang_lim xiao_lin susanto_rahardja feng_pan	a adaptive edgepreserving artifact removal filter for video postprocessing		ISCAS_(5)	
425052	hongtao_yu zhiping_lin feng_pan	a improved rate control algorithm for h 264		ISCAS_(1)	Sch._of_Electr._&_Electron._Eng. Nanyang_Technol._Univ. Singapore Singapore
430117	zhiping_lin hongtao_yu feng_pan	a scalable fast mode decision algorithm for h 264		ISCAS	Sch._of_Electr._&_Electron._Eng. Nanyang_Technol._Univ. Singapore
473148	feng_pan gao_cong anthony_k._h._tung jiong_yang mohammed_javeed_zaki	carpenter finding close pattern in long biological dataset	the growth of bioinformatic have result in dataset with new characteristic these dataset typically contain a large number of column and a small number of row for example many gene expression dataset may contain 10000100 000 column but only 1001000 rowssuch dataset pose a great challenge for exist lrb close rrb frequent pattern discovery algorithm since they have a exponential dependence on the average row length in this paper we describe a new algorithm call carpenter that be specially design to handle dataset have a large number of attribute and relatively small number of row several experiment on real bioinformatic dataset show that carpenter be order of magnitude better than previous closed pattern mining algorithm like closet and charm doi 101145 956750956832 mining charm closed pattern closet ter	KDD	Natl._University_of_Singapore
475340	feng_pan kenny_choo thinh_m._le	fast ratedistortion optimization in h 264avc video coding		KES_(3)	
475341	feng_pan h._men thinh_m._le	block standstill and homogeneity base fast motion estimation algorithm for h 264 video coding	the paper propose a fast motion estimation algorithm base on the spatial homogeneity and temporal standstill of video sequence it classify a frame into different region such as standstill stationary or dynamic region for mb lie in the standstill region motion estimation be skip for mb lie in the stationary region motion estimation be apply once to a mb in the region and the result motion vector will be use by other mb in the same region normal motion estimation be only carry out in the dynamic region the new algorithm can be use either by itself alone or by combine with other exist fast motion estimation method experimental result show that the new algorithm can significantly improve the time efficiency of the h 264 encoder and be able to achieve a average reduction of 27 in encode with a average psnr loss of only 009 db and 042 bit rate increase compare with the original h 264 reference software doi 101007 1155393961 standstill psnr motion estimation rdo mbs	KES_(3)	
511635	feng_pan robert_farrell	computing semantic similarity between skill statements for approximate match	this paper explore the problem of compute text similarity between verb phrase describe skilled human behavior for the purpose of find approximate match four parser be evaluate on a large corpus of skill statement extract from a enterprisewide expertise taxonomy a similarity measure utilize common semantic role feature extract from parse tree be find superior to a information theoretic measure of similarity and comparable to the level of human agreement semantic role parse trees parser text similarity skill statement	HLT-NAACL	
532046	r._yu keng_pang_lim dajun_wu feng_pan zhengguo_li genan_feng si_wu	a 2stage partial distortion search algorithm for block motion estimation		IEEE_Pacific_Rim_Conference_on_Multimedia	
559356	xiang_zhang feng_pan yuying_xie fei_zou wei_wang	coe a general approach for efficient genomewide twolocus epistasis test in disease association study	the availability of highdensity single nucleotide polymorphism lrb snp rrb datum have make genomewide association study computationally challenging twolocus epistasis lrb genegene interaction rrb detection have attract great research interest as a promising method for genetic analysis of complex disease in this article we propose a general approach coe for efficient large scale genegene interaction analysis which support a wide range of test in particular we show that many commonly use statistics be convex function from the observe value of the event in twolocus association test we can develop a upper bind of the test value such a upper bind only depend on singlelocus test and the genotype of the snppair we thus group and index snppair by they genotype this indexing structure can benefit the computation of all convex statistics utilize the upper bind and the indexing structure we can prune most of the snppair without compromise the optimality of the result we approach be especially efficient for large permutation test extensive experiment demonstrate that we approach provide order of magnitude performance improvement over the brute force approach doi 101089 cmb 20090155 snppair genomewide association study single nucleotide polymorphism snp general approach epistasis	RECOMB	Department_of_Computer_Science University_of_North_Carolina_at_Chapel_Hill
598434	gao_cong anthony_k._h._tung xin_xu feng_pan jiong_yang	farmer finding interesting rule group in microarray datasets	microarray dataset typically contain large number of column but small number of row association rule have be prove to be useful in analyze such dataset however most existing association rule mining algorithm be unable to efficiently handle dataset with large number of column moreover the number of association rule generate from such dataset be enormous due to the large number of possible column combinationsin this paper we describe a new algorithm call farmer that be specially design to discover association rule from microarray dataset instead of find individual association rule farmer find b interesting rule group b which be essentially a set of rule that be generate from the same set of row unlike conventional rule mining algorithm farmer search for interesting rule in the row enumeration space and exploit all userspecified constraint include minimum support confidence and chisquare to support efficient pruning several experiment on real bioinformatic dataset show that farmer be order of magnitude faster than previous association rule mining algorithm doi 101145 10075681007587 mining svm association rule gene expression datum microarray	SIGMOD_Conference	
600269	feng_pan xiang_zhang wei_wang	crd fast coclustering on large dataset utilize samplingbased matrix decomposition	the problem of simultaneously cluster column and row lrb coclustering rrb arise in important application such as text datum mining microarray analysis and recommendation system analysis compare with the classical clustering algorithm coclustering algorithm have be show to be more effective in discover hidden clustering structure in the datum matrix the complexity of previous coclustering algorithm be usually i o i lrb i m i x i n i rrb where i m i and i n i be the number of row and column in the datum matrix respectively this limit they applicability to datum matrix involve a large number of column and row moreover some huge dataset can not be entirely hold in main memory during coclustering which violate the assumption make by the previous algorithm in this paper we propose a general framework for fast coclustering large dataset i crd i by utilize recently develop samplingbased matrix decomposition method i crd i achieve a execution time linear in i m i and i n i also i crd i do not require the whole datum matrix be in the main memory we conduct extensive experiment on both real and synthetic datum compare with previous coclustering algorithm i crd i achieve competitive accuracy but with much less computational cost doi 101145 13766161376637 datum matrix rows and columns coclustering crd main memory	SIGMOD_Conference	University_of_North_Carolina_at_Chapel_Hill Chapel_Hill NC USA
618209	feng_pan anthony_k._h._tung gao_cong xin_xu	cobbler combining column and row enumeration for closed pattern discovery	the problem of mining frequent close pattern have receive considerable attention recently as it promise to have much less redundancy compare to discover all frequent pattern exist algorithm can presently be separate into two group feature lrb column rrb 1 enumeration and row enumeration feature enumeration algorithm like charm and closet be efficient for dataset with small number of feature and large number of row since the number of feature combination to be enumerate be small row enumeration algorithm like carpenter on the other hand be more suitable for dataset lrb eg bioinformatic datum rrb with large number of feature and small number of row both group of algorithm however will encounter problem for dataset that have large number of row and feature in this paper we describe a new algorithm call cobbler which can efficiently mine such dataset cobbler be design to dynamically switch between feature enumeration and row enumeration depend on the datum characteristic in the process of mining as such each portion of the dataset can be process use the most suitable method make the mining more efficient several experiment on reallife and synthetic dataset show that cobbler be a order of magnitude better than previous closed pattern mining algorithm like charm closet and carpenter doi 101109 ssdbm 200421 mining charm cob bler enumeration	SSDBM	National_University_of_Singapore
628545	feng_pan jerry_r._hobbs	temporal arithmetic mixing month and day	in this paper we present we work on create a complete set of rule for temporal arithmetic mix month and day base on the historydependent intuition many example be present for demonstrate how the rule be use and how the computation satisfy various desire arithmetic property such as the subtraction commutativity and associativity property a notion of day lose lrb dl rrb be propose to concisely keep track of the history of the temporal arithmetic computation and explain possible inconsistency in term of different desire property doi 101109 time 200628 arithmetic commutativity associativity complete set subtraction	TIME	University_of_Southern_California
692142	lini_ma feng_pan	efficient compression of multiview video use hierarchical b picture		MUE	Dept._of_Comput._Sci. Beijing_Inf._Sci._&_Technol._Univ. Beijing
729959	shuying_zhao chengdong_wu feng_pan yunzhou_zhang	the exploration and practice of talents foster mode about information science in countryoriented informationbased strategy	institutes and college need keep explore the way of talent foster about information science and put it into practice as the strategy of innovative countryoriented construction and the development of state informationize in this paper we analyze the opportunity and challenge bring by the strategy be analyze the process and result of practice be summarize accord to the practical work and some thinking be expound in foster talent about information science at the same time doi 101109 csse 2008480	CSSE_(5)	Sch._of_Inf._Sci._&_Eng. Northeastern_Univ. Shenyang China
830032	alexander_gutfraind aric_a._hagberg feng_pan	optimal interdiction of unreactive markovian evader	the interdiction problem arise in a variety of area include military logistics infectious disease control and counterterrorism in the typical formulation of network interdiction the task of the interdictor be to find a set of edge in a weighted network such that the removal of those edge would maximally increase the cost to a evader of travel on a path through the network we work be motivate by case in which the evader have incomplete information about the network or lack planning time or computational power eg when authority set up roadblock to catch bank robber the criminal do not know all the roadblock location or the best path to use for they escape we introduce a model of network interdiction in which the motion of one or more evader be describe by markov process and the evader be assume not to react to interdiction decision the interdiction objective be to find a edge set of size b that maximize the probability of capture the evader we prove that similar to the standard leastcost formulation for deterministic motion this interdiction problem be also nphard but unlike that problem we interdiction problem be submodular and the optimal solution can be approximate within 1 1e use a greedy algorithm additionally we exploit submodularity through a priority evaluation strategy that eliminate the linear complexity scaling in the number of network edge and speed up the solution by order of magnitude take together the result bring closer the goal of find realistic solution to the interdiction problem on globalscale network doi 101007 97836420192969 interdiction evader ume	CoRR	Risk_Analysis_and_Decision_Support_Systems Los_Alamos_National_Laboratory Los_Alamos New_Mexico_87545
1024854	feng_pan david_p._morton	minimize a stochastic maximumreliability path	we consider a stochastic network interdiction problem in which the goal be to detect a evader who select a maximumreliability path subject to a resource constraint the interdictor install sensor on a subset of the network s arc to minimize the value of the evader s maximumreliability path ie to maximize the detection probability when this decision be make the evader s origin destination pair be know to the interdictor only through a probability distribution we model be frame as a stochastic mixedinteger program and solve by a enhance lshaped decomposition method we primary enhancement be via a valid inequality which we call a step inequality in earlier work lsb morton et al iie trans 39 lrb 2007 rrb 3 14 rsb we develop step inequality for the special case in which the evader encounter at most one sensor on a origin destination path here we generalize the step inequality to the case where the evader encounter multiple sensor in this more general setting the step inequality be tightly couple to the decomposition scheme a efficient separation algorithm identify violate step inequality and strengthen the linear programming relaxation of the lshaped method s master program we apply this solution procedure with further computational enhancement to a collection of test problem doi 101002 net 20238 interdictor evader arc stochastic network interdiction decomposition method	Networks	D-6_Risk_Analysis_and_Decision_Support_Systems Los_Alamos_National_Laboratory Los_Alamos New_Mexico_87545
1045327	feng_pan	adaptive image compression use local pattern information		Pattern_Recognition_Letters	School_of_EEE Centre_for_Signal_Processing Nanyang_Technological_University 639798_Singapore Singapore
1077446	jerry_r._hobbs feng_pan	a ontology of time for the semantic web	in connection with the daml project for bring about the semantic web a ontology of time be be develop for describe the temporal content of web page and the temporal property of web service this ontology cover topological property of instant and interval measure of duration and the meaning of clock and calendar term doi 101145 10170681017073 instant time ontology owl owltime temporal	ACM_Trans._Asian_Lang._Inf._Process.	University_of_Southern_California
1097075	zhengguo_li ce_zhu nam_ling xiaokang_yang genan_feng si_wu feng_pan	a unified architecture for realtime videocoding system		IEEE_Trans._Circuits_Syst._Video_Techn.	Media_Div. Inst._for_InfoComm_Res. Singapore
1097159	feng_pan zengguo_li keng_pang_lim genan_feng	a study of mpeg4 rate control scheme and its improvement		IEEE_Trans._Circuits_Syst._Video_Techn.	Inst._for_Infocomm_Res. Singapore
1097161	feng_pan xiao_lin susanto_rahardja keng_pang_lim z._g._li dajun_wu si_wu	fast mode decision algorithm for intraprediction in h 264avc video code	the h 264avc video code standard aim to enable significantly improve compression performance compare to all exist video code standard in order to achieve this a robust ratedistortion optimization lrb rdo rrb technique be employ to select the best coding mode and reference frame for each macroblock as a result the complexity and computation load increase drastically this paper present a fast mode decision algorithm for h 264avc intraprediction base on local edge information prior to intraprediction a edge map be create and a local edge direction histogram be then establish for each subblock base on the distribution of the edge direction histogram only a small part of intraprediction mode be choose for rdo calculation experimental result show that the fast intraprediction mode decision scheme increase the speed of intracode significantly with negligible loss of peak signaltonoise ratio doi 101109 tcsvt 2005848356 h 264avc rdo avc intra video coding	IEEE_Trans._Circuits_Syst._Video_Techn.	Inst._for_Infocomm_Res. Singapore Singapore
1097431	dajun_wu feng_pan keng_pang_lim si_wu zhengguo_li xiao_lin susanto_rahardja chi_chung_ko	fast intermode decision in h 264avc video code		IEEE_Trans._Circuits_Syst._Video_Techn.	Inst._for_Infocomm_Res. Singapore Singapore
1126126	vincent_w._freeh david_k._lowenthal feng_pan nandini_kappiah robert_springer barry_rountree mark_e._femal	analyze the energytime tradeoff in highperformance computing application	although user of highperformance computing be most interested in raw performance both energy and power consumption have become critical concern one approach to lower energy and power be to use highperformance cluster node that have several powerperformance state so that the energytime tradeoff can be dynamically adjust this paper analyze the energytime tradeoff of a wide range of applicationsserial and parallelon a powerscalable cluster we use a cluster of frequency and voltagescalable amd64 node each equip with a power meter we study the effect of memory and communication bottleneck via direct measurement of time and energy we also investigate metric that can at runtime predict when each type of bottleneck occur we result show that for program that have a memory or communication bottleneck a powerscalable cluster can save significant energy with only a small time penalty furthermore we find that for some program it be possible to both consume less energy and execute in less time by increase the number of node while reduce the frequencyvoltage setting of each node doi 101109 tpds 20071026 mpo wide range of application frequency scale cpu gear	IEEE_Trans._Parallel_Distrib._Syst.	Dept._of_Comput._Sci. North_Carolina_State_Univ. Raleigh NC
1143477	feng_pan z._p._lin xiao_lin susanto_rahardja w._juwono f._slamet	adaptive frame skip base on spatiotemporal complexity for low bitrate video code		J._Visual_Communication_and_Image_Representation	
1143496	zhengguo_li wen_gao feng_pan s._w._ma keng_pang_lim g._n._feng xiao_lin susanto_rahardja h._q._lu yan_lu	adaptive rate control for h 264	this paper present a rate control scheme for h 264 by introduce the concept of basic unit and a linear prediction model the basic unit can be a macroblock lrb mb rrb a slice or a frame it can be use to obtain a tradeoff between the overall code efficiency and the bit fluctuation the linear model be use to solve the chicken and egg dilemma exist in the rate control of h 264 both constant bit rate lrb cbr rrb and variable bit rate lrb vbr rrb case be study we scheme have be adopt by h 264 doi 101016 jjvcir 200504004 rate control dilemma rdo egg mad	J._Visual_Communication_and_Image_Representation	Media_Div. Inst._for_Infocomm_Res. Singapore Singapore
1184607	xianfang_wang zhiyong_du jindong_chen feng_pan	dynamic modeling of biotechnical process base on online support vector machine	due to the complexity and high nonlinearity of biotechnical process most simple mathematical model can not describe the behavior of biochemistry system very well therefore dynamic modeling of biotechnical process be indispensable support vector machine lrb svm rrb be a novel machine learning method which be powerful for the problem characterize by small sample nonlinearity high dimension and local minima and have high generalization but currently most support vector machine regression lrb svr rrb training algorithm be offline which could not be suit for timevariant system so a improve svm call online support vector machine be present to modeling for the dynamic feature of fermentation process the model base on the modify svm be develop and demonstrate use simulation experiment some model base on svm be also present the result show that the modeling base online svm be superior to modeling base on svw doi 104304 jcp43251258 nonlinearity svm suit fermentation process small sample	JCP	
1185453	weiqi_luo zhenhua_qu feng_pan jiwu_huang	a survey of passive technology for digital image forensic	over the past year digital image have be widely use in the internet and other application whilst image processing technique be develop at a rapid speed tamper with digital image without leave any obvious trace become easier and easier this may give rise to some problem such as image authentication a new passive technology for image forensic have evolve quickly during the last few year unlike the signaturebased or watermark base method the new technology do not need any signature generate or watermark embedded in advance it assume that different imaging device or processing would introduce different inherent pattern into the output image these underlie pattern be consistent in the original untampered image and would be alter after some kind of manipulation thus they can be use as evidence for image source identification and alteration detection in this paper we will discuss this new forensic technology and give a overview of the prior literature some conclude remark be make about the state of the art and the challenge in this novel technology doi 101007 s1170400700170 authentication watermark digital image image forensics passive technology	Frontiers_of_Computer_Science_in_China	
1186041	xiang_zhang feng_pan wei_wang andrew_b._nobel	mining nonredundant high order correlation in binary datum	many approach have be propose to find correlation in binary datum usually these method focus on pairwise correlation in biology application it be important to find correlation that involve more than just two feature moreover a set of strongly correlate feature should be nonredundant in the sense that the correlation be strong only when all the interact feature be consider together remove any feature will greatly reduce the correlationin this paper we explore the problem of find nonredundant high order correlation in binary datum the high order correlation be formalize use multiinformation a generalization of pairwise mutual information to reduce the redundancy we require any subset of a strongly correlate feature subset to be weakly correlate such feature subset be refer to as nonredundant interacting feature subset lrb nif rrb find all nifss be computationally challenging because in addition to enumerate feature combination we also need to check all they subset for redundancy we study several property of nifss and show that these property be useful in develop efficient algorithm we further develop two set of upper and lower bound on the correlation which can be incorporate in the algorithm to prune the search space a simple and effective pruning strategy base on pairwise mutual information be also develop to further prune the search space the efficiency and effectiveness of we approach be demonstrate through extensive experiment on synthetic and reallife dataset mutual information nif high order correlation multi binary data	PVLDB	University_of_North_Carolina_at_Chapel_Hill
1201411	feng_pan	digital video coding technique and standards		Intelligent_Multimedia_Data_Hiding:_New_Directions	
1207555	bin_xin jie_chen feng_pan	problem difficulty analysis for particle swarm optimization deception and modality	this paper study the problem difficulty for a popular optimization method particle swarm optimization lrb pso rrb particularly for the pso variant psocf lrb pso with constriction factor rrb and analyze its predictive measure some previous measure and related issue about other optimizer mainly include deception and modality be check for pso it be observe that deception be mainly the combination of three factor the measure ratio of attraction basin the relative distance of attractor and the relative difference of attractor altitude multimodality and multifunnel be prove not to be the essential factor contribute to the problem difficulty for pso the counterexample and comparative experiment in this paper can be take as a reference for further research on novel comprehensive predictive measure of problem difficulty for pso doi 101145 15438341543919 attractor pso deception particle swarm optimization problem difficulty	GEC_Summit	Department_of_Automatic_Control Beijing_Institute_of_Technology Beijing China
1207666	feng_pan guanghui_wang yang_liu	a multiobjectivebased nonstationary uav assignment model for constraint handle use pso	a unmanned aerial vehicle lrb uav rrb assignment require allocate vehicle to destination to complete various job it be a complex assignment problem with hard constraint and potential dimensional explosion when the scenario become more complicated and the size of problem increase moreover the nonstationary uav assignment problem study in the paper be more difficult since dynamic scenario be introduce eg change of the number or different task requirement of target and vehicle etc in this paper a constraintfirstobjective next model be propose for the nonstationary problem the propose model can effectively handle constraint as a additional objective include constraint express by nature language and be flexible enough to be combine with kind of intelligent computation algorithm a local version of pso be cooperate with the propose model to solve nonstationary uav assignment problem numerical experimental result illustrate that it can efficiently achieve the optima and demonstrate the effectiveness doi 101145 15438341543896 pso nonstationary	GEC_Summit	Beijing_Institute_of_Technology Beijing China
1239501	feng_pan tim_converse david_ahn franco_salvetti gianluca_donato	feature selection for ranking use boost tree	modern search engine have to be fast to satisfy user so there be hard backend latency requirement the set of feature useful for search ranking function though continue to grow make feature computation a latency bottleneck as a result not all available feature can be use for ranking and in fact much of the time only a small percentage of these feature can be use thus it be crucial to have a feature selection mechanism that can find a subset of feature that both meet latency requirement and achieve high relevance to this end we explore different feature selection method use boost regression tree include both greedy approach lrb select the feature with highest relative importance as compute by boost tree discount importance by feature similarity and a randomize approach we evaluate and compare these approach use datum from a commercial search engine the experimental result show that the propose randomize feature selection with featureimportancebased backward elimination outperform greedy approach and achieve a comparable relevance with 30 feature to a fullfeature model train with 419 feature and the same modeling parameter doi 101145 16459531646292 greedy approaches ranking function feature selection regression trees wrapper	CIKM	Microsoft_/_Powerset San_Francisco CA USA
1274010	min_xia jian'an_fang feng_pan en'jian_bai	robust sequence memory in sparselyconnected network with controllable steadystate period		Neurocomputing	College_of_Information_Science_and_Technology Donghua_University Shanghai_201620 China
1286072	feng_pan jiongbin_chen jiwu_huang	discriminate between photorealistic computer graphic and natural image use fractal geometry	render technology in computer graphic lrb cg rrb be now capable of produce highly photorealistic image give rise to the problem of how to identify cg image from natural image some method be propose to solve this problem in this paper we give a novel method from a new point of view of image perception although the photorealistic cg image be very similar to natural image they be surrealistic and smoother than natural image thus lead to the difference in perception a part of feature be derive from fractal dimension to capture the difference in color perception between cg image and natural image and several generalize dimension be use as the rest feature to capture difference in coarseness the effect of these feature be verify by experiment the average accuracy be over 912 doi 101007 s1143200900535	Science_in_China_Series_F:_Information_Sciences	
1286198	jie_chen bin_xin zhihong_peng feng_pan	statistical learning make the hybridization of particle swarm and differential evolution more efficient a novel hybrid optimizer	this brief paper report a hybrid algorithm we develop recently to solve the global optimization problem of multimodal function by combine the advantage of two powerful populationbased metaheuristic differential evolution lrb de rrb and particle swarm optimization lrb pso rrb in the hybrid denote by depso each individual in one generation choose its evolution method de or pso in a statistical learning way the choice depend on the relative success ratio of the two method in a previous learning period the propose depso be compare with its pso and de parent two advanced de variant one of which be suggest by the originator of de two advance pso variant one of which be acknowledge as a recent standard by pso community and also a previous depso benchmark test demonstrate that the depso be more competent for the global optimization of multimodal function due to its high optimization quality the global optimization of multimodal function be one of the most important generic topic in scientific and engineering research since many problem can be depict in its form particle swarm optimization lrb pso rrb and differential evolution lrb de rrb be two kind of powerful populationbased metaheuristic algorithm for numerical optimization lsb 12 rsb both pso and de have attract much attention from researcher in different field in the past decade lsb 1 8 rsb the goal of this brief paper be to report on a novel powerful hybrid optimizer we propose by combine the advantage of pso and de the rest of this paper be outline as follow in section 1 a brief introduction on the pso and de optimizer for hybridization be provide in section 2 a novel hybrid algorithm base on pso and de be propose in section 3 numerical experiment base on several benchmark problem be implement to compare the performance of different optimizer section 4 conclude the paper doi 101007 s1143200901194 pso optimizer global optimization depso hybridization	Science_in_China_Series_F:_Information_Sciences	
1290569	danhong_liu xia_wang feng_pan yongyong_xu peng_yang keqin_rao	webbased infectious disease reporting use xml form	objective explore solution for infectious disease information sharing among hospital and public health information system be imperative to the improvement of disease surveillance and emergent response this paper aim at develop a method to directly transmit realtime datum of notifiable infectious disease from hospital information system to public health information system on the internet by use a standard extensible markup language lrb xml rrb format method the mechanism and work flow by which notifiable infectious disease datum be create report and use at health agency in china be evaluate the capacity of all participate provider to use electronic datum interchange to submit transaction of datum require for the notifiable infectious disease reporting be assess the minimum datum set at national level that be require for report for national notifiable infectious disease surveillance be determine the standard and technique available worldwide for electronic health datum interchange such as xml hl7 messaging cda and atsm ccr etc be review and compare and a xml implementation format need for this purpose be define for hospital that be able to access the internet to provide a complete infectious disease reporting result there be 18703 county or city hospital in china all of they have access to basic information infrastructure include computer email and the internet nearly 10000 hospital possess hospital information system use for electronically record retrieve and manipulate patient information these system collect 23 datum item require in the minimum data set for national notifiable infectious disease reporting in order to transmit these datum item to the disease surveillance system and local health information system instantly and without duplication of datum input a xml schema and a set of standard datum element be develop to define the content structure and semantics of the data set these standard make it possible to view and analyse the datum accurately outside the hospital information system in many different document format the paper also identify other issue involve in notifiable disease reporting in the future such as the adoption of approve vocabulary standard and implementation problem such as the route secure transfer parsing and objective identify of the xml message conclusion xml be a increasingly important standard for exchange and transmission of datum between disparate application and system as in its early stage of develop a interoperable health information system in china the xml document structure could be a way to exchange the notifiable case information among interest party on the web at present doi 101016 jijmedinf 200710011	Synthesis_Lectures_on_Computer_Vision	
1302001	feng_pan min_xia en'jian_bai	a new hybrid model for timeseries prediction	this paper propose a new hybrid model in order to increase time series prediction accuracy this hybrid model consider the routine time prediction technique like ar ann or any other as atomic building block a linear hybrid technique be use to combine they forecast result into the final result the hybrid algorithm be test against three different kind of time series datum experiment result show the effectiveness of the propose hybrid model doi 101109 coginf 20095250728	null	Coll._of_Inf._Sci._&_Technol. Donghua_Univ. Shanghai China
1329252	feng_pan rucheng_han runsheng_zhang	a optimal controller basedon ga for direct torque control	in direct torque control lrb dtc rrb of induction motor the performance of system be influence by the give value of torque the give torque be the output of speed regulator and pid adjustor be use generally as the speed regulator so the selection of pid parameter be crucial to dtc system in this paper a new optimal control strategy of dtc basedon genetic algorithm lrb ga rrb for induction motor be present in this method ga be use to optimize the pid parameter of speed regulator so the precision of give torque be improve and the dynamic response of torque be more satisfying than traditional dtc the result of simulation indicate the validity of this method doi 101109 wgec 200959	null	Electr._Inf._Eng._Coll. Taiyuan_Univ._of_Sci._&_Technol. Taiyuan China
1370694	feng_pan z._g._li k._p._lim d._j._wu r._s._yu g._n._feng	a adaptive rate control algorithm for video code over personal digital assistant lrb pda rrb	with the recent development of thirdgeneration communication technology encode live video use a pda and share it among friend have become a reality however the embedded processor inside a pda be still not powerful enough and there be two major hurdle to overcome lrb 1 rrb video code need to meet the rigorous constraint of the available computation capacity of a pda lrb 2 rrb in a pda the computing power allocate to video coding may vary drastically lrb in burst rrb in this paper a new adaptive rate control algorithm be propose for video code over a pda this adaptive rate control scheme take into account the time constraint of a pda and its bit allocation depend not only on the available datum bit but more importantly on the available coding time experimental result show that compare to the exist rate control scheme the new algorithm can always achieve the maximum frame rate maximize the utilization of the available bandwidth and computing power increase the average psnr and improve the subjective perceptual quality of the reconstructed video doi 101109 icme 20031221681 psnr buffer rate control video coding pda	Proceedings_of_the_2003_International_Conference_on_Multimedia_and_Expo_-_Volume_1	Inst._for_Infocomm_Res. A-STAR Singapore
1752846	xianfang_wang jindong_chen zhou_wu feng_pan	modeling of fermentation process base on qdpsosvm		Proceedings_of_the_2008_Fourth_International_Conference_on_Natural_Computation_-_Volume_07	Sch._of_Commun._&_Control_Eng. Jiangnan_Univ. Wuxi
